<html>
<head>
<title>BLE IMU Example</title>
<script src="gl-matrix.js"></script>
<style>
body
{
background-color:#ffffff;
}

p,h1,h2,h3,li,td,div
{ 
font-family: helvetica, sans-serif;
color:#000000;
font-size: medium; 
}
</style>
</head>
<body>



<button>Start</button>

<div id="noBLE" style="display:none">
This demo requires Web BLE, which is only available on new Chrome browsers on Android Chrome, Chromeboxes, 
some Macs and Windows PCs. It's not supported on other browsers (Firefox, Safari, Edge, Internet Explorer)
and is not supported on Chrome for iOS.
</div>

<div id="error"></div>

<div>&nbsp;</div>

<div id="graphDiv">
    <canvas id="glcanvas" width="640" height="480"></canvas>
</div> <!-- graphDiv -->


<script>

var roll = 0, pitch = 0, yaw = 0;

document.querySelector('button').addEventListener('click', function() {
	if (navigator.bluetooth) {
		onButtonClick();
	}
	else {
		document.getElementById('noBLE').style.removeProperty('display');
	}
});

async function onButtonClick() {
	try {
		console.log('requesting bluetooth device...');
		const device = await navigator.bluetooth.requestDevice({
			filters: [{services: ['a2916c31-22b3-4284-93ba-8a784fa0baff']}]});

		console.log('connecting to GATT server...');
		const server = await device.gatt.connect();

		console.log('getting private imu service...');
		const service = await server.getPrimaryService('a2916c31-22b3-4284-93ba-8a784fa0baff');

		console.log('getting private potentiometer characteristic...');
		const characteristic = await service.getCharacteristic('b871bee1-e621-40db-8d31-4c86b2acfebb');

		console.log('starting notifications...');		
		await characteristic.startNotifications();

		console.log('notifications started, adding listener');
		characteristic.addEventListener('characteristicvaluechanged', handleNotifications);

		// Hide the instructions
		document.getElementById('instructions').style.display = 'none';

	} catch(error) {
		console.log('error: ' + error);
		document.getElementById('error').innerHTML = error;
	}
}

function handleNotifications(event) {
	// value are in signed 32-bit floats in little endian byte order (true)
	// Adafruit unified sensor library outputs degrees
	var x = event.target.value.getFloat32(0, true);
	var y = event.target.value.getFloat32(4, true);
	var z = event.target.value.getFloat32(8, true);

	//console.log("x=" + x + " y=" + y + " z=" + z);

	// z = roll  Rotation around the longitudinal axis (the plane body, 'X axis'). Roll is positive and increasing when moving downward. -90deg<=roll<=90deg */
    // y = pitch Rotation around the lateral axis (the wing span, 'Y axis'). Pitch is positive and increasing when moving upwards. -180deg<=pitch<=180deg) */
    // x = heading (yaw) Angle between the longitudinal axis (the plane body) and magnetic north, measured clockwise when viewing from the top of the device. 0-359deg */
	// Note: x, y, z are as the IMU is positioned in the example, not the "traditional" meaning of x, y, z!
            
    // Web GL transformation is axis to rotate around (X, Y, Z) in radians
    // instead of roll, pitch, heading. Transform that here.
	
    // The values are also negative because the signs seem reversed from Web GL
    
	roll = -y * 0.0174533;  // [0, 0, 1]
	yaw = -x * 0.0174533;   // [0, 1, 0]
	pitch = -z * 0.0174533; // [1, 0, 0]
}

// Modified version of:
// https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API/Tutorial/Using_textures_in_WebGL




var cubeRotation = 0.0;

main();

//
// Start here
//
function main() {
	const canvas = document.querySelector('#glcanvas');
	const gl = canvas.getContext('webgl') || canvas.getContext('experimental-webgl');

	// If we don't have a GL context, give up now

	if (!gl) {
		alert('Unable to initialize WebGL. Your browser or machine may not support it.');
		return;
	}

	// Vertex shader program

	const vsSource = `
		attribute vec4 aVertexPosition;
		attribute vec4 aVertexColor;

		uniform mat4 uModelViewMatrix;
		uniform mat4 uProjectionMatrix;

		varying lowp vec4 vColor;

		void main(void) {
		gl_Position = uProjectionMatrix * uModelViewMatrix * aVertexPosition;
		vColor = aVertexColor;
		}
		`;

	// Fragment shader program

	const fsSource = `
		varying lowp vec4 vColor;

		void main(void) {
		gl_FragColor = vColor;
		}
		`;

	// Initialize a shader program; this is where all the lighting
	// for the vertices and so forth is established.
	const shaderProgram = initShaderProgram(gl, vsSource, fsSource);

	// Collect all the info needed to use the shader program.
	// Look up which attributes our shader program is using
	// for aVertexPosition, aVevrtexColor and also
	// look up uniform locations.
	const programInfo = {
			program: shaderProgram,
			attribLocations: {
				vertexPosition: gl.getAttribLocation(shaderProgram, 'aVertexPosition'),
				vertexColor: gl.getAttribLocation(shaderProgram, 'aVertexColor'),
			},
			uniformLocations: {
				projectionMatrix: gl.getUniformLocation(shaderProgram, 'uProjectionMatrix'),
				modelViewMatrix: gl.getUniformLocation(shaderProgram, 'uModelViewMatrix'),
			},
	};

	// Here's where we call the routine that builds all the
	// objects we'll be drawing.
	const buffers = initBuffers(gl);

	var then = 0;

	// Draw the scene repeatedly
	function render(now) {
		now *= 0.001;  // convert to seconds
		const deltaTime = now - then;
		then = now;

		drawScene(gl, programInfo, buffers, deltaTime);

		requestAnimationFrame(render);
	}
	requestAnimationFrame(render);
}

//
// initBuffers
//
// Initialize the buffers we'll need. For this demo, we just
// have one object -- a simple three-dimensional cube.
//
function initBuffers(gl) {

	// Create a buffer for the cube's vertex positions.

	const positionBuffer = gl.createBuffer();

	// Select the positionBuffer as the one to apply buffer
	// operations to from here out.

	gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);

	// Now create an array of positions for the cube.

	const positions = [
		// Front face
		-1.0, -0.05,  0.5,
		1.0, -0.05,  0.5,
		1.0,  0.05,  0.5,
		-1.0,  0.05,  0.5,

		// Back face
		-1.0, -0.05, -0.5,
		-1.0,  0.05, -0.5,
		1.0,  0.05, -0.5,
		1.0, -0.05, -0.5,

		// Top face
		-1.0,  0.05, -0.5,
		-1.0,  0.05,  0.5,
		1.0,  0.05,  0.5,
		1.0,  0.05, -0.5,

		// Bottom face
		-1.0, -0.05, -0.5,
		1.0, -0.05, -0.5,
		1.0, -0.05,  0.5,
		-1.0, -0.05,  0.5,

		// Right face
		1.0, -0.05, -0.5,
		1.0,  0.05, -0.5,
		1.0,  0.05,  0.5,
		1.0, -0.05,  0.5,

		// Left face
		-1.0, -0.05, -0.5,
		-1.0, -0.05,  0.5,
		-1.0,  0.05,  0.5,
		-1.0,  0.05, -0.5,
		];
	
	// Now pass the list of positions into WebGL to build the
	// shape. We do this by creating a Float32Array from the
	// JavaScript array, then use it to fill the current buffer.

	gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(positions), gl.STATIC_DRAW);

	// Now set up the colors for the faces. We'll use solid colors
	// for each face.

	const faceColors = [
		[0.4,  0.4,  0.4,  1.0],    // Front face: gray
		[0.4,  0.4,  0.4,  1.0],    // Back face: grey
		[0.0,  0.0,  0.0,  1.0],    // Top face: black
		[0.3,  0.3,  0.3,  1.0],    // Bottom face: dark gray
		[0.4,  0.4,  0.4,  1.0],    // Right face: gray
		[0.4,  0.4,  0.4,  1.0],    // Left face: gray
		];

	// Convert the array of colors into a table for all the vertices.

	var colors = [];

	for (var j = 0; j < faceColors.length; ++j) {
		const c = faceColors[j];

		// Repeat each color four times for the four vertices of the face
		colors = colors.concat(c, c, c, c);
	}

	const colorBuffer = gl.createBuffer();
	gl.bindBuffer(gl.ARRAY_BUFFER, colorBuffer);
	gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(colors), gl.STATIC_DRAW);

	// Build the element array buffer; this specifies the indices
	// into the vertex arrays for each face's vertices.

	const indexBuffer = gl.createBuffer();
	gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, indexBuffer);

	// This array defines each face as two triangles, using the
	// indices into the vertex array to specify each triangle's
	// position.

	const indices = [
		0,  1,  2,      0,  2,  3,    // front
		4,  5,  6,      4,  6,  7,    // back
		8,  9,  10,     8,  10, 11,   // top
		12, 13, 14,     12, 14, 15,   // bottom
		16, 17, 18,     16, 18, 19,   // right
		20, 21, 22,     20, 22, 23,   // left
		];

	// Now send the element array to GL

	gl.bufferData(gl.ELEMENT_ARRAY_BUFFER,
			new Uint16Array(indices), gl.STATIC_DRAW);

	return {
		position: positionBuffer,
		color: colorBuffer,
		indices: indexBuffer,
	};
}

//
// Draw the scene.
//
function drawScene(gl, programInfo, buffers, deltaTime) {
	gl.clearColor(1.0, 1.0, 1.0, 1.0);  // Clear to white, fully opaque
	gl.clearDepth(1.0);                 // Clear everything
	gl.enable(gl.DEPTH_TEST);           // Enable depth testing
	gl.depthFunc(gl.LEQUAL);            // Near things obscure far things

	// Clear the canvas before we start drawing on it.

	gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

	// Create a perspective matrix, a special matrix that is
	// used to simulate the distortion of perspective in a camera.
	// Our field of view is 45 degrees, with a width/height
	// ratio that matches the display size of the canvas
	// and we only want to see objects between 0.1 units
	// and 100 units away from the camera.

	const fieldOfView = 45 * Math.PI / 180;   // in radians
	const aspect = gl.canvas.clientWidth / gl.canvas.clientHeight;
	const zNear = 0.1;
	const zFar = 100.0;
	const projectionMatrix = mat4.create();

	// note: glmatrix.js always has the first argument
	// as the destination to receive the result.
	mat4.perspective(projectionMatrix,
			fieldOfView,
			aspect,
			zNear,
			zFar);

	// Set the drawing position to the "identity" point, which is
	// the center of the scene.
	const modelViewMatrix = mat4.create();

	// Now move the drawing position a bit to where we want to
	// start drawing the square.

	mat4.translate(modelViewMatrix,     // destination matrix
			modelViewMatrix,     // matrix to translate
			[-0.0, 0.0, -6.0]);  // amount to translate
	mat4.rotate(modelViewMatrix,  // destination matrix
			modelViewMatrix,  // matrix to rotate
			roll,     // amount to rotate in radians
			[0, 0, 1]);       // axis to rotate around (Z) (roll)
	mat4.rotate(modelViewMatrix,  // destination matrix
			modelViewMatrix,  // matrix to rotate
			yaw,// amount to rotate in radians
			[0, 1, 0]);       // axis to rotate around (Y) (yaw)
	mat4.rotate(modelViewMatrix,  // destination matrix
			modelViewMatrix,  // matrix to rotate
			pitch, // amount to rotate in radians
			[1, 0, 0]);       // axis to rotate around (X) (pitch)

			
	// If we rotate +0.5 radians around the X axis [1, 0, 0], it's like looking down from
	// slightly in front and above with translation [0.0, 0.0, -6.0].
			
	// Tell WebGL how to pull out the positions from the position
	// buffer into the vertexPosition attribute
	{
		const numComponents = 3;
		const type = gl.FLOAT;
		const normalize = false;
		const stride = 0;
		const offset = 0;
		gl.bindBuffer(gl.ARRAY_BUFFER, buffers.position);
		gl.vertexAttribPointer(
				programInfo.attribLocations.vertexPosition,
				numComponents,
				type,
				normalize,
				stride,
				offset);
		gl.enableVertexAttribArray(
				programInfo.attribLocations.vertexPosition);
	}

	// Tell WebGL how to pull out the colors from the color buffer
	// into the vertexColor attribute.
	{
		const numComponents = 4;
		const type = gl.FLOAT;
		const normalize = false;
		const stride = 0;
		const offset = 0;
		gl.bindBuffer(gl.ARRAY_BUFFER, buffers.color);
		gl.vertexAttribPointer(
				programInfo.attribLocations.vertexColor,
				numComponents,
				type,
				normalize,
				stride,
				offset);
		gl.enableVertexAttribArray(
				programInfo.attribLocations.vertexColor);
	}

	// Tell WebGL which indices to use to index the vertices
	gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, buffers.indices);

	// Tell WebGL to use our program when drawing

	gl.useProgram(programInfo.program);

	// Set the shader uniforms

	gl.uniformMatrix4fv(
			programInfo.uniformLocations.projectionMatrix,
			false,
			projectionMatrix);
	gl.uniformMatrix4fv(
			programInfo.uniformLocations.modelViewMatrix,
			false,
			modelViewMatrix);

	{
		const vertexCount = 36;
		const type = gl.UNSIGNED_SHORT;
		const offset = 0;
		gl.drawElements(gl.TRIANGLES, vertexCount, type, offset);
	}

	// Update the rotation for the next draw

	//cubeRotation += deltaTime;
}

//
// Initialize a shader program, so WebGL knows how to draw our data
//
function initShaderProgram(gl, vsSource, fsSource) {
	const vertexShader = loadShader(gl, gl.VERTEX_SHADER, vsSource);
	const fragmentShader = loadShader(gl, gl.FRAGMENT_SHADER, fsSource);

	// Create the shader program

	const shaderProgram = gl.createProgram();
	gl.attachShader(shaderProgram, vertexShader);
	gl.attachShader(shaderProgram, fragmentShader);
	gl.linkProgram(shaderProgram);

	// If creating the shader program failed, alert

	if (!gl.getProgramParameter(shaderProgram, gl.LINK_STATUS)) {
		alert('Unable to initialize the shader program: ' + gl.getProgramInfoLog(shaderProgram));
		return null;
	}

	return shaderProgram;
}

//
// creates a shader of the given type, uploads the source and
// compiles it.
//
function loadShader(gl, type, source) {
	const shader = gl.createShader(type);

	// Send the source to the shader object

	gl.shaderSource(shader, source);

	// Compile the shader program

	gl.compileShader(shader);

	// See if it compiled successfully

	if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
		alert('An error occurred compiling the shaders: ' + gl.getShaderInfoLog(shader));
		gl.deleteShader(shader);
		return null;
	}

	return shader;
}



</script>

<div id="instructions">

<p>This is the BLE IMU example. It allows a Gen 3 device to communicate directly with
your web browser if you have:</p>

<ul>
<li>An Android phone (Chrome browser) with Bluetooth support</li>
<li>A Chromebook</li>
<li>Some Macs, using Chrome (does not work with Firefax, Safari, etc.)</li>
<li>Some Windows PC, using Chrome (does not work with Firefox, Edge, Internet Explorer, etc.)</li>
<li>Not an iOS phone or iPad! (Does not work even on Chrome for iOS)</li>
</ul>

<p>The really cool thing is that there's no server processing the data. The orientation data from the IMU is sent by 
BLE from the Argon directly to your computer, Android phone, or Chromebook where it's rendered. The rendering is done 
using WebGL with nothing done on the server, and no browser plug-ins required!</p>

<p>Here's a video of it in action. </p>

<video width="640" height="360" controls>
  <source src="video.mp4" type="video/mp4">
</video>

<p>It requires the <a href="https://www.adafruit.com/product/2472">Adafruit BNO055 IMU</a>, "9-DOF Absolute Orientation IMU Fusion Breakout."</p>

<p><img src="circuit.jpg" /></p>

<p>Connect:</p>

<ul>
<li>VIN to 3V3 (red)</li>
<li>GND to GND (black)</li>
<li>SDA to SDA/D0 (green)</li>
<li>SCL to SCL/D1 (blue)</li>
</ul>

<p>Be sure to position it in the same way on the breadboard, otherwise you'll have to modify the code to change the sign of roll and pitch.</p>

<p>And here's the code to flash to your device. Be sure to include the Adafruit_BNO055_RK library.</p>

<pre>
#include "Particle.h"

#include "Adafruit_BNO055_RK.h"


SYSTEM_MODE(MANUAL);

Adafruit_BNO055 bno = Adafruit_BNO055(55);

const BleUuid serviceUuid("a2916c31-22b3-4284-93ba-8a784fa0baff");
const BleUuid valueUuid("b871bee1-e621-40db-8d31-4c86b2acfebb");

BleCharacteristic valueCharacteristic("value", BleCharacteristicProperty::NOTIFY, valueUuid, serviceUuid);

const unsigned long UPDATE_PERIOD_MS = 100;
unsigned long lastUpdate = 0;

void setup() {
	Serial.begin();

	if (!bno.begin()) {
		Log.info("Failed to initialize BNO055");
	}


	BLE.addCharacteristic(valueCharacteristic);

	BleAdvertisingData data;
	data.appendServiceUUID(serviceUuid);
	BLE.advertise(&data);
}

typedef union {
	struct {
		float x;
		float y;
		float z;
	} sample;
	uint8_t bytes[12];
} Sample;

void loop() {
	if (BLE.connected()) {
		if (millis() - lastUpdate >= UPDATE_PERIOD_MS) {
			lastUpdate = millis();

			sensors_event_t event;
			bno.getEvent(&event);

			Sample sample;
			sample.sample.x = event.orientation.x;
			sample.sample.y = event.orientation.y;
			sample.sample.z = event.orientation.z;

			valueCharacteristic.setValue(sample.bytes, sizeof(Sample));
		}
	}
}
</pre>

</div>

</body>
</html>